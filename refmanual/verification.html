
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Forecast verification (pysteps.verification) &#8212; pysteps 0.2 documentation</title>
    <link rel="stylesheet" href="../_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Visualization (pysteps.visualization)" href="visualization.html" />
    <link rel="prev" title="Miscellaneous utility functions (pysteps.utils)" href="utils.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="visualization.html" title="Visualization (pysteps.visualization)"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="utils.html" title="Miscellaneous utility functions (pysteps.utils)"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">pysteps 0.2 documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="forecast-verification-pysteps-verification">
<span id="pysteps-verification"></span><h1>Forecast verification (<code class="xref py py-mod docutils literal notranslate"><span class="pre">pysteps.verification</span></code>)<a class="headerlink" href="#forecast-verification-pysteps-verification" title="Permalink to this headline">¶</a></h1>
<p>Methods for verification of deterministic and ensemble forecasts.</p>
<div class="section" id="pysteps-verification-detcatscores">
<h2>pysteps.verification.detcatscores<a class="headerlink" href="#pysteps-verification-detcatscores" title="Permalink to this headline">¶</a></h2>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#pysteps.verification.detcatscores.det_cat_fcst" title="pysteps.verification.detcatscores.det_cat_fcst"><code class="xref py py-obj docutils literal notranslate"><span class="pre">det_cat_fcst</span></code></a>(pred,&nbsp;obs,&nbsp;thr,&nbsp;scores)</td>
<td>Calculate simple and skill scores for deterministic categorical forecasts.</td>
</tr>
</tbody>
</table>
<span class="target" id="module-pysteps.verification.detcatscores"></span><p>Forecast evaluation and skill scores for deterministic categorial forecasts.</p>
<dl class="function">
<dt id="pysteps.verification.detcatscores.det_cat_fcst">
<code class="descclassname">pysteps.verification.detcatscores.</code><code class="descname">det_cat_fcst</code><span class="sig-paren">(</span><em>pred</em>, <em>obs</em>, <em>thr</em>, <em>scores</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.detcatscores.det_cat_fcst" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate simple and skill scores for deterministic categorical forecasts.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>pred</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">predictions</p>
</dd>
<dt><strong>obs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">verifying observations</p>
</dd>
<dt><strong>scores</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd><p class="first">a list containing the names of the scores to be computed, the full list
is:</p>
<table border="1" class="last docutils">
<colgroup>
<col width="18%" />
<col width="82%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Name</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>ACC</td>
<td>accuracy (proportion correct)</td>
</tr>
<tr class="row-odd"><td>BIAS</td>
<td>frequency bias</td>
</tr>
<tr class="row-even"><td>CSI</td>
<td>critical success index (threat score)</td>
</tr>
<tr class="row-odd"><td>FA</td>
<td>false alarm rate (prob. of false detection)</td>
</tr>
<tr class="row-even"><td>FAR</td>
<td>false alarm ratio</td>
</tr>
<tr class="row-odd"><td>GSS</td>
<td>Gilbert skill score (equitable threat score)</td>
</tr>
<tr class="row-even"><td>HK</td>
<td>Hanssen-Kuipers discriminant (Pierce skill score)</td>
</tr>
<tr class="row-odd"><td>HSS</td>
<td>Heidke skill score</td>
</tr>
<tr class="row-even"><td>POD</td>
<td>probability of detection (hit rate)</td>
</tr>
<tr class="row-odd"><td>SEDI</td>
<td>symmetric extremal dependency index</td>
</tr>
</tbody>
</table>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>result</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd><p class="first last">the verification results</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="pysteps-verification-detcontscores">
<h2>pysteps.verification.detcontscores<a class="headerlink" href="#pysteps-verification-detcontscores" title="Permalink to this headline">¶</a></h2>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#pysteps.verification.detcontscores.det_cont_fcst" title="pysteps.verification.detcontscores.det_cont_fcst"><code class="xref py py-obj docutils literal notranslate"><span class="pre">det_cont_fcst</span></code></a>(pred,&nbsp;obs,&nbsp;scores,&nbsp;**kwargs)</td>
<td>Calculate simple and skill scores for deterministic continuous forecasts</td>
</tr>
</tbody>
</table>
<span class="target" id="module-pysteps.verification.detcontscores"></span><p>Forecast evaluation and skill scores for deterministic continuous forecasts.</p>
<dl class="function">
<dt id="pysteps.verification.detcontscores.det_cont_fcst">
<code class="descclassname">pysteps.verification.detcontscores.</code><code class="descname">det_cont_fcst</code><span class="sig-paren">(</span><em>pred</em>, <em>obs</em>, <em>scores</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.detcontscores.det_cont_fcst" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate simple and skill scores for deterministic continuous forecasts</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>pred</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">predictions</p>
</dd>
<dt><strong>obs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">verifying observations</p>
</dd>
<dt><strong>scores</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd><p class="first">a list containing the names of the scores to be computed, the full list
is:</p>
<table border="1" class="last docutils">
<colgroup>
<col width="16%" />
<col width="84%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Name</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>beta</td>
<td>linear regression slope (conditional bias)</td>
</tr>
<tr class="row-odd"><td>corr_p</td>
<td>pearson’s correleation coefficien (linear correlation)</td>
</tr>
<tr class="row-even"><td>corr_s</td>
<td>spearman’s correlation coefficient (rank correlation)</td>
</tr>
<tr class="row-odd"><td>ME_add</td>
<td>mean error or bias of additive residuals</td>
</tr>
<tr class="row-even"><td>ME_mult</td>
<td>mean error or bias of multiplicative residuals</td>
</tr>
<tr class="row-odd"><td>RMSE_add</td>
<td>root mean squared additive error</td>
</tr>
<tr class="row-even"><td>RMSE_mult</td>
<td>root mean squared multiplicative error</td>
</tr>
<tr class="row-odd"><td>RV_add</td>
<td>reduction of variance (Brier Score, Nash-Sutcliffe Efficiency)</td>
</tr>
<tr class="row-even"><td>RV_mult</td>
<td>reduction of variance in multiplicative space</td>
</tr>
<tr class="row-odd"><td>scatter</td>
<td>half the distance between the 16% and 84% percentiles of the
error distribution</td>
</tr>
</tbody>
</table>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first docutils">
<dt><strong>result</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd><p class="first last">list containing the verification results</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-odd field"><th class="field-name" colspan="2">Other Parameters:</th></tr>
<tr class="field-odd field"><td>&#160;</td><td class="field-body"><dl class="first last docutils">
<dt><strong>offset</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">an offset that is added to both prediction and observation to avoid 0 division
when computing multiplicative residuals. Default is 0.01.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="pysteps-verification-ensscores">
<h2>pysteps.verification.ensscores<a class="headerlink" href="#pysteps-verification-ensscores" title="Permalink to this headline">¶</a></h2>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#pysteps.verification.ensscores.ensemble_skill" title="pysteps.verification.ensscores.ensemble_skill"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ensemble_skill</span></code></a>(X_f,&nbsp;X_o,&nbsp;metric,&nbsp;**kwargs)</td>
<td>Compute mean ensemble skill for a given skill metric.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#pysteps.verification.ensscores.ensemble_spread" title="pysteps.verification.ensscores.ensemble_spread"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ensemble_spread</span></code></a>(X_f,&nbsp;metric,&nbsp;**kwargs)</td>
<td>Compute mean ensemble spread for a given skill metric.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#pysteps.verification.ensscores.rankhist_init" title="pysteps.verification.ensscores.rankhist_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rankhist_init</span></code></a>(num_ens_members,&nbsp;X_min)</td>
<td>Initialize a rank histogram object.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#pysteps.verification.ensscores.rankhist_accum" title="pysteps.verification.ensscores.rankhist_accum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rankhist_accum</span></code></a>(rankhist,&nbsp;X_f,&nbsp;X_o)</td>
<td>Accumulate forecast-observation pairs to the given rank histogram.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#pysteps.verification.ensscores.rankhist_compute" title="pysteps.verification.ensscores.rankhist_compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rankhist_compute</span></code></a>(rankhist[,&nbsp;normalize])</td>
<td>Return the rank histogram counts and optionally normalize the histogram.</td>
</tr>
</tbody>
</table>
<span class="target" id="module-pysteps.verification.ensscores"></span><p>Evaluation and skill scores for ensemble forecasts.</p>
<dl class="function">
<dt id="pysteps.verification.ensscores.ensemble_skill">
<code class="descclassname">pysteps.verification.ensscores.</code><code class="descname">ensemble_skill</code><span class="sig-paren">(</span><em>X_f</em>, <em>X_o</em>, <em>metric</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.ensscores.ensemble_skill" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute mean ensemble skill for a given skill metric.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X_f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd><p class="first last">Array of shape (l,m,n) containing the forecast fields of shape (m,n)
from l ensemble members.</p>
</dd>
<dt><strong>X_o</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">Array of shape (m,n) containing the observed field corresponding to
the forecast.</p>
</dd>
<dt><strong>metric</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">The deterministic skill metric to be used (list available in
<code class="xref py py-func docutils literal notranslate"><span class="pre">get_method()</span></code>)</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first docutils">
<dt><strong>out</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">The mean skill of all ensemble members that is used as defintion of
ensemble skill (as in Zacharov and Rezcova 2009 with the FSS).</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-odd field"><th class="field-name" colspan="2">Other Parameters:</th></tr>
<tr class="field-odd field"><td>&#160;</td><td class="field-body"><dl class="first last docutils">
<dt><strong>thr</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Intensity threshold for categorical scores.</p>
</dd>
<dt><strong>scale</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The spatial scale to verify in px. In practice it represents the size of
the moving window that it is used to compute the fraction of pixels above
the threshold for the FSS.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<p>[ZR2009]</p>
</dd></dl>

<dl class="function">
<dt id="pysteps.verification.ensscores.ensemble_spread">
<code class="descclassname">pysteps.verification.ensscores.</code><code class="descname">ensemble_spread</code><span class="sig-paren">(</span><em>X_f</em>, <em>metric</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.ensscores.ensemble_spread" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute mean ensemble spread for a given skill metric.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X_f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd><p class="first last">Array of shape (l,m,n) containing the forecast fields of shape (m,n)
from l ensemble members.</p>
</dd>
<dt><strong>metric</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">The skill metric to be used, the list includes:</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first docutils">
<dt><strong>out</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">The mean skill compted between all possible pairs of the ensemble members,
which can be used as definition of mean ensemble spread (as in Zacharov
and Rezcova 2009 with the FSS).</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-odd field"><th class="field-name" colspan="2">Other Parameters:</th></tr>
<tr class="field-odd field"><td>&#160;</td><td class="field-body"><dl class="first last docutils">
<dt><strong>thr</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Intensity threshold for categorical scores.</p>
</dd>
<dt><strong>scale</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The spatial scale to verify in px. In practice it represents the size of
the moving window that it is used to compute the fraction of pixels above
the threshold for the FSS.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<p>[ZR2009]</p>
</dd></dl>

<dl class="function">
<dt id="pysteps.verification.ensscores.rankhist_accum">
<code class="descclassname">pysteps.verification.ensscores.</code><code class="descname">rankhist_accum</code><span class="sig-paren">(</span><em>rankhist</em>, <em>X_f</em>, <em>X_o</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.ensscores.rankhist_accum" title="Permalink to this definition">¶</a></dt>
<dd><p>Accumulate forecast-observation pairs to the given rank histogram.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X_f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd><p class="first last">Array of shape (k,m,n,…) containing the values from an ensemble 
forecast of k members with shape (m,n,…).</p>
</dd>
<dt><strong>X_o</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">Array of shape (m,n,…) containing the observed values corresponding 
to the forecast.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pysteps.verification.ensscores.rankhist_compute">
<code class="descclassname">pysteps.verification.ensscores.</code><code class="descname">rankhist_compute</code><span class="sig-paren">(</span><em>rankhist</em>, <em>normalize=True</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.ensscores.rankhist_compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the rank histogram counts and optionally normalize the histogram.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>rankhist</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">A rank histogram object created with rankhist_init.</p>
</dd>
<dt><strong>normalize</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd><p class="first last">If True, normalize the rank histogram so that the bin counts sum to one.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>out</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">The counts for the n+1 bins in the rank histogram, where n is the number
of ensemble members.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pysteps.verification.ensscores.rankhist_init">
<code class="descclassname">pysteps.verification.ensscores.</code><code class="descname">rankhist_init</code><span class="sig-paren">(</span><em>num_ens_members</em>, <em>X_min</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.ensscores.rankhist_init" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize a rank histogram object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>num_ens_members</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Number ensemble members in the forecasts to accumulate into the rank
histogram.</p>
</dd>
<dt><strong>X_min</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Threshold for minimum intensity. Forecast-observation pairs, where all
ensemble members and verifying observations are below X_min, are not
counted in the rank histogram.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>out</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">The rank histogram object.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="pysteps-verification-plots">
<h2>pysteps.verification.plots<a class="headerlink" href="#pysteps-verification-plots" title="Permalink to this headline">¶</a></h2>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#pysteps.verification.plots.plot_intensityscale" title="pysteps.verification.plots.plot_intensityscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_intensityscale</span></code></a>(iss[,&nbsp;fig,&nbsp;vmin,&nbsp;vmax,&nbsp;…])</td>
<td>Plot a intensity-scale verification table with a color bar and axis labels.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#pysteps.verification.plots.plot_rankhist" title="pysteps.verification.plots.plot_rankhist"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_rankhist</span></code></a>(rankhist[,&nbsp;ax])</td>
<td>Plot a rank histogram.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#pysteps.verification.plots.plot_reldiag" title="pysteps.verification.plots.plot_reldiag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_reldiag</span></code></a>(reldiag[,&nbsp;ax])</td>
<td>Plot a reliability diagram.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#pysteps.verification.plots.plot_ROC" title="pysteps.verification.plots.plot_ROC"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_ROC</span></code></a>(ROC[,&nbsp;ax,&nbsp;opt_prob_thr])</td>
<td>Plot a ROC curve.</td>
</tr>
</tbody>
</table>
<span class="target" id="module-pysteps.verification.plots"></span><dl class="function">
<dt id="pysteps.verification.plots.plot_ROC">
<code class="descclassname">pysteps.verification.plots.</code><code class="descname">plot_ROC</code><span class="sig-paren">(</span><em>ROC</em>, <em>ax=None</em>, <em>opt_prob_thr=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.plots.plot_ROC" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot a ROC curve.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>ROC</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">A ROC curve object created by probscores.ROC_curve_init.</p>
</dd>
<dt><strong>ax</strong> <span class="classifier-delimiter">:</span> <span class="classifier">axis handle</span></dt>
<dd><p class="first last">Axis handle for the figure. If set to None, the handle is taken from
the current figure (matplotlib.pylab.gca()).</p>
</dd>
<dt><strong>opt_prob_thr</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd><p class="first last">If set to True, plot the optimal probability threshold that maximizes 
the difference between the hit rate (POD) and false alarm rate (POFD).</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pysteps.verification.plots.plot_intensityscale">
<code class="descclassname">pysteps.verification.plots.</code><code class="descname">plot_intensityscale</code><span class="sig-paren">(</span><em>iss</em>, <em>fig=None</em>, <em>vmin=-2</em>, <em>vmax=1</em>, <em>kmperpixel=None</em>, <em>unit=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.plots.plot_intensityscale" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot a intensity-scale verification table with a color bar and axis
labels.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>iss</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">An intensity-scale verification results dictionary returned by
pysteps.verification.spatialscores.intensity_scale.</p>
</dd>
<dt><strong>fig</strong> <span class="classifier-delimiter">:</span> <span class="classifier">matplotlib.figure.Figure</span></dt>
<dd><p class="first last">Optional figure object to use for plotting. If not supplied, a new
figure is created.</p>
</dd>
<dt><strong>vmin</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Optional minimum value for the intensity-scale skill score in the plot.
Defaults to -2.</p>
</dd>
<dt><strong>vmax</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Optional maximum value for the intensity-scale skill score in the plot.
Defaults to 1.</p>
</dd>
<dt><strong>kmperpixel</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Optional conversion factor from pixels to kilometers. If supplied,
the unit of the shown spatial scales is km instead of pixels.</p>
</dd>
<dt><strong>unit</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string</span></dt>
<dd><p class="first last">Optional unit of the intensity thresholds.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pysteps.verification.plots.plot_rankhist">
<code class="descclassname">pysteps.verification.plots.</code><code class="descname">plot_rankhist</code><span class="sig-paren">(</span><em>rankhist</em>, <em>ax=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.plots.plot_rankhist" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot a rank histogram.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>rankhist</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">A rank histogram object created by ensscores.rankhist_init.</p>
</dd>
<dt><strong>ax</strong> <span class="classifier-delimiter">:</span> <span class="classifier">axis handle</span></dt>
<dd><p class="first last">Axis handle for the figure. If set to None, the handle is taken from
the current figure (matplotlib.pylab.gca()).</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pysteps.verification.plots.plot_reldiag">
<code class="descclassname">pysteps.verification.plots.</code><code class="descname">plot_reldiag</code><span class="sig-paren">(</span><em>reldiag</em>, <em>ax=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.plots.plot_reldiag" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot a reliability diagram.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>reldiag</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">A ROC curve object created by probscores.reldiag_init.</p>
</dd>
<dt><strong>ax</strong> <span class="classifier-delimiter">:</span> <span class="classifier">axis handle</span></dt>
<dd><p class="first last">Axis handle for the figure. If set to None, the handle is taken from
the current figure (matplotlib.pylab.gca()).</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="pysteps-verification-probscores">
<h2>pysteps.verification.probscores<a class="headerlink" href="#pysteps-verification-probscores" title="Permalink to this headline">¶</a></h2>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#pysteps.verification.probscores.CRPS" title="pysteps.verification.probscores.CRPS"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CRPS</span></code></a>(X_f,&nbsp;X_o)</td>
<td>Compute the average continuous ranked probability score (CRPS) for a set of forecast ensembles and the corresponding observations.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#pysteps.verification.probscores.reldiag_init" title="pysteps.verification.probscores.reldiag_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reldiag_init</span></code></a>(X_min[,&nbsp;n_bins,&nbsp;min_count])</td>
<td>Initialize a reliability diagram object.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#pysteps.verification.probscores.reldiag_accum" title="pysteps.verification.probscores.reldiag_accum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reldiag_accum</span></code></a>(reldiag,&nbsp;P_f,&nbsp;X_o)</td>
<td>Accumulate the given probability-observation pairs into the reliability diagram.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#pysteps.verification.probscores.reldiag_compute" title="pysteps.verification.probscores.reldiag_compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reldiag_compute</span></code></a>(reldiag)</td>
<td>Compute the x- and y- coordinates of the points in the reliability diagram.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#pysteps.verification.probscores.ROC_curve_init" title="pysteps.verification.probscores.ROC_curve_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ROC_curve_init</span></code></a>(X_min[,&nbsp;n_prob_thrs])</td>
<td>Initialize a ROC curve object.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#pysteps.verification.probscores.ROC_curve_accum" title="pysteps.verification.probscores.ROC_curve_accum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ROC_curve_accum</span></code></a>(ROC,&nbsp;P_f,&nbsp;X_o)</td>
<td>Accumulate the given probability-observation pairs into the given ROC object.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#pysteps.verification.probscores.ROC_curve_compute" title="pysteps.verification.probscores.ROC_curve_compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ROC_curve_compute</span></code></a>(ROC[,&nbsp;compute_area])</td>
<td>Compute the ROC curve and its area from the given ROC object.</td>
</tr>
</tbody>
</table>
<span class="target" id="module-pysteps.verification.probscores"></span><p>Evaluation and skill scores for probabilistic forecasts.</p>
<dl class="function">
<dt id="pysteps.verification.probscores.CRPS">
<code class="descclassname">pysteps.verification.probscores.</code><code class="descname">CRPS</code><span class="sig-paren">(</span><em>X_f</em>, <em>X_o</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.probscores.CRPS" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the average continuous ranked probability score (CRPS) for a set
of forecast ensembles and the corresponding observations.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X_f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">Array of shape (n,m) containing n ensembles of forecast values with each
ensemble having m members.</p>
</dd>
<dt><strong>X_o</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">Array of n observed values.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>out</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">The continuous ranked probability score.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<p>[Her2000]</p>
</dd></dl>

<dl class="function">
<dt id="pysteps.verification.probscores.ROC_curve_accum">
<code class="descclassname">pysteps.verification.probscores.</code><code class="descname">ROC_curve_accum</code><span class="sig-paren">(</span><em>ROC</em>, <em>P_f</em>, <em>X_o</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.probscores.ROC_curve_accum" title="Permalink to this definition">¶</a></dt>
<dd><p>Accumulate the given probability-observation pairs into the given ROC
object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>ROC</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">A ROC curve object created with ROC_curve_init.</p>
</dd>
<dt><strong>P_f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">Forecasted probabilities for exceeding the threshold specified in the ROC
object. Non-finite values are ignored.</p>
</dd>
<dt><strong>X_o</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">Observed values. Non-finite values are ignored.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pysteps.verification.probscores.ROC_curve_compute">
<code class="descclassname">pysteps.verification.probscores.</code><code class="descname">ROC_curve_compute</code><span class="sig-paren">(</span><em>ROC</em>, <em>compute_area=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.probscores.ROC_curve_compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the ROC curve and its area from the given ROC object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>ROC</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">A ROC curve object created with ROC_curve_init.</p>
</dd>
<dt><strong>compute_area</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd><p class="first last">If True, compute the area under the ROC curve (between 0.5 and 1).</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>out</strong> <span class="classifier-delimiter">:</span> <span class="classifier">tuple</span></dt>
<dd><p class="first last">A two-element tuple containing the probability of detection (POD) and
probability of false detection (POFD) for the probability thresholds
specified in the ROC curve object. If compute_area is True, return the
area under the ROC curve as the third element of the tuple.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pysteps.verification.probscores.ROC_curve_init">
<code class="descclassname">pysteps.verification.probscores.</code><code class="descname">ROC_curve_init</code><span class="sig-paren">(</span><em>X_min</em>, <em>n_prob_thrs=10</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.probscores.ROC_curve_init" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize a ROC curve object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X_min</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Precipitation intensity threshold for yes/no prediction.</p>
</dd>
<dt><strong>n_prob_thrs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The number of probability thresholds to use. The interval [0,1] is divided
into n_prob_thrs evenly spaced values.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>out</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">The ROC curve object.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pysteps.verification.probscores.reldiag_accum">
<code class="descclassname">pysteps.verification.probscores.</code><code class="descname">reldiag_accum</code><span class="sig-paren">(</span><em>reldiag</em>, <em>P_f</em>, <em>X_o</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.probscores.reldiag_accum" title="Permalink to this definition">¶</a></dt>
<dd><p>Accumulate the given probability-observation pairs into the reliability
diagram.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>reldiag</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">A reliability diagram object created with reldiag_init.</p>
</dd>
<dt><strong>P_f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd><p class="first last">Forecast probabilities for exceeding the intensity threshold specified
in the reliability diagram object.</p>
</dd>
<dt><strong>X_o</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span></dt>
<dd><p class="first last">Observed values.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pysteps.verification.probscores.reldiag_compute">
<code class="descclassname">pysteps.verification.probscores.</code><code class="descname">reldiag_compute</code><span class="sig-paren">(</span><em>reldiag</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.probscores.reldiag_compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the x- and y- coordinates of the points in the reliability diagram.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>reldiag</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">A reliability diagram object created with reldiag_init.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>out</strong> <span class="classifier-delimiter">:</span> <span class="classifier">tuple</span></dt>
<dd><p class="first last">Two-element tuple containing the x- and y-coordinates of the points in
the reliability diagram.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pysteps.verification.probscores.reldiag_init">
<code class="descclassname">pysteps.verification.probscores.</code><code class="descname">reldiag_init</code><span class="sig-paren">(</span><em>X_min</em>, <em>n_bins=10</em>, <em>min_count=10</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.probscores.reldiag_init" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize a reliability diagram object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X_min</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Precipitation intensity threshold for yes/no prediction.</p>
</dd>
<dt><strong>n_bins</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Number of bins to use in the reliability diagram.</p>
</dd>
<dt><strong>min_count</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Minimum number of samples required for each bin. A zero value is assigned
if the number of samples in a bin is smaller than bin_count.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>out</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">The reliability diagram object.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<p>[BS2007]</p>
</dd></dl>

</div>
<div class="section" id="pysteps-verification-spatialscores">
<h2>pysteps.verification.spatialscores<a class="headerlink" href="#pysteps-verification-spatialscores" title="Permalink to this headline">¶</a></h2>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#pysteps.verification.spatialscores.binary_mse" title="pysteps.verification.spatialscores.binary_mse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">binary_mse</span></code></a>(X_f,&nbsp;X_o,&nbsp;thr[,&nbsp;wavelet])</td>
<td>Compute an intensity-scale verification as the MSE of the binary error.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#pysteps.verification.spatialscores.intensity_scale_init" title="pysteps.verification.spatialscores.intensity_scale_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">intensity_scale_init</span></code></a>(name,&nbsp;thrs[,&nbsp;scales,&nbsp;…])</td>
<td>Initialize an intensty-scale verification object.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#pysteps.verification.spatialscores.intensity_scale_accum" title="pysteps.verification.spatialscores.intensity_scale_accum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">intensity_scale_accum</span></code></a>(iss,&nbsp;X_f,&nbsp;X_o)</td>
<td>Compute and update the intensity-scale verification scores.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#pysteps.verification.spatialscores.fss" title="pysteps.verification.spatialscores.fss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fss</span></code></a>(X_f,&nbsp;X_o,&nbsp;thr,&nbsp;scale)</td>
<td>Compute the fractions skill score (FSS) for a deterministic forecast field and the corresponding observation.</td>
</tr>
</tbody>
</table>
<span class="target" id="module-pysteps.verification.spatialscores"></span><p>Skill scores for spatial forecasts.</p>
<dl class="function">
<dt id="pysteps.verification.spatialscores.binary_mse">
<code class="descclassname">pysteps.verification.spatialscores.</code><code class="descname">binary_mse</code><span class="sig-paren">(</span><em>X_f</em>, <em>X_o</em>, <em>thr</em>, <em>wavelet='haar'</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.spatialscores.binary_mse" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute an intensity-scale verification as the MSE of the binary error.
This method uses PyWavelets for decomposing the error field between the
forecasts and observations into multiple spatial scales.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X_f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">Array of shape (n,m) containing the forecast field.</p>
</dd>
<dt><strong>X_o</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">Array of shape (n,m) containing the verification observation field.</p>
</dd>
<dt><strong>thr</strong> <span class="classifier-delimiter">:</span> <span class="classifier">sequence</span></dt>
<dd><p class="first last">The intensity threshold for which to compute the verification.</p>
</dd>
<dt><strong>wavelet</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">The name of the wavelet function to use. Defaults to the Haar wavelet,
as described in Casati et al. 2004. See the documentation of PyWavelets
for a list of available options.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>SS</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">One-dimensional array containing the binary MSE for each spatial scale.</p>
</dd>
<dt><strong>spatial_scale</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<p>[CRS2004]</p>
</dd></dl>

<dl class="function">
<dt id="pysteps.verification.spatialscores.fss">
<code class="descclassname">pysteps.verification.spatialscores.</code><code class="descname">fss</code><span class="sig-paren">(</span><em>X_f</em>, <em>X_o</em>, <em>thr</em>, <em>scale</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.spatialscores.fss" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the fractions skill score (FSS) for a deterministic forecast
field and the corresponding observation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X_f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">Array of shape (n,m) containing the forecast field.</p>
</dd>
<dt><strong>X_o</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">Array of shape (n,m) containing the reference field (observation).</p>
</dd>
<dt><strong>thr</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Intensity threshold.</p>
</dd>
<dt><strong>scale</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The spatial scale  in px. In practice they represent the size of the
moving window that it is used to compute the fraction of pixels above
the threshold.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>out</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">The fractions skill score between 0 and 1.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<p>[RL2008], [EWWM2013]</p>
</dd></dl>

<dl class="function">
<dt id="pysteps.verification.spatialscores.intensity_scale_accum">
<code class="descclassname">pysteps.verification.spatialscores.</code><code class="descname">intensity_scale_accum</code><span class="sig-paren">(</span><em>iss</em>, <em>X_f</em>, <em>X_o</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.spatialscores.intensity_scale_accum" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute and update the intensity-scale verification scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>iss</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">An intensity-scale object created with intensity_scale_init.</p>
</dd>
<dt><strong>X_f</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">Array of shape (n,m) containing the forecast field.</p>
</dd>
<dt><strong>X_o</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">Array of shape (n,m) containing the verification observation field.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>iss</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first">A dictionary with the following key-value pairs:</p>
<table border="1" class="last docutils">
<colgroup>
<col width="21%" />
<col width="79%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Key</th>
<th class="head">Value</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>name</td>
<td>the name of the intensity-scale skill score</td>
</tr>
<tr class="row-odd"><td>SS</td>
<td>two-dimensional array containing the intensity-scale
skill scores for each spatial scale and intensity
threshold</td>
</tr>
<tr class="row-even"><td>scales</td>
<td>the spatial scales,
corresponds to the first index of SS</td>
</tr>
<tr class="row-odd"><td>thrs</td>
<td>the used intensity thresholds in increasing order,
corresponds to the second index of SS</td>
</tr>
<tr class="row-even"><td>n</td>
<td>the number of verified fct-obs pairs that were
averaged</td>
</tr>
<tr class="row-odd"><td>shape</td>
<td>the shape of the fct-obs fields</td>
</tr>
</tbody>
</table>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pysteps.verification.spatialscores.intensity_scale_init">
<code class="descclassname">pysteps.verification.spatialscores.</code><code class="descname">intensity_scale_init</code><span class="sig-paren">(</span><em>name</em>, <em>thrs</em>, <em>scales=None</em>, <em>wavelet='Haar'</em><span class="sig-paren">)</span><a class="headerlink" href="#pysteps.verification.spatialscores.intensity_scale_init" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize an intensty-scale verification object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>score_names</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string</span></dt>
<dd><p class="first">A string indicating the name of the spatial verification score to be used:</p>
<table border="1" class="last docutils">
<colgroup>
<col width="18%" />
<col width="82%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Name</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>FSS</td>
<td>Fractions skill score</td>
</tr>
<tr class="row-odd"><td>BMSE</td>
<td>Binary mean squared error</td>
</tr>
</tbody>
</table>
</dd>
<dt><strong>thrs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">sequence</span></dt>
<dd><p class="first last">A sequence of intensity thresholds for which to compute the verification.</p>
</dd>
<dt><strong>scales</strong> <span class="classifier-delimiter">:</span> <span class="classifier">sequence</span></dt>
<dd><p class="first last">A sequence of spatial scales in pixels to be used in the FSS.</p>
</dd>
<dt><strong>wavelet</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">The name of the wavelet function to use in the BMSE. Defaults to the Haar
wavelet, as described in Casati et al. 2004. See the documentation of
PyWavelets for a list of available options.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>iss</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">The intensity-scale object.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="utils.html"
                        title="previous chapter">Miscellaneous utility functions (<code class="docutils literal notranslate"><span class="pre">pysteps.utils</span></code>)</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="visualization.html"
                        title="next chapter">Visualization (<code class="docutils literal notranslate"><span class="pre">pysteps.visualization</span></code>)</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="visualization.html" title="Visualization (pysteps.visualization)"
             >next</a> |</li>
        <li class="right" >
          <a href="utils.html" title="Miscellaneous utility functions (pysteps.utils)"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">pysteps 0.2 documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2018, Seppo Pulkkinen, Daniele Nerini and Loris Foresti.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.2.
    </div>
  </body>
</html>